{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JltnSoj3fW0",
        "outputId": "02109edb-d82e-4cd5-8d84-2cebd12dd340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id       asins   brand                  categories  \\\n",
            "0  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
            "1  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
            "2  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
            "3  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
            "4  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
            "\n",
            "  colors             dateAdded           dateUpdated  \\\n",
            "0    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
            "1    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
            "2    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
            "3    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
            "4    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
            "\n",
            "                  dimension  ean                         keys  ...  \\\n",
            "0  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
            "1  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
            "2  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
            "3  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
            "4  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
            "\n",
            "  reviews.rating                                 reviews.sourceURLs  \\\n",
            "0            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
            "1            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
            "2            4.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
            "3            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
            "4            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
            "\n",
            "                                        reviews.text  \\\n",
            "0  I initially had trouble deciding between the p...   \n",
            "1  Allow me to preface this with a little history...   \n",
            "2  I am enjoying it so far. Great for reading. Ha...   \n",
            "3  I bought one of the first Paperwhites and have...   \n",
            "4  I have to say upfront - I don't like coroporat...   \n",
            "\n",
            "                                reviews.title reviews.userCity  \\\n",
            "0              Paperwhite voyage, no regrets!              NaN   \n",
            "1           One Simply Could Not Ask For More              NaN   \n",
            "2  Great for those that just want an e-reader              NaN   \n",
            "3                    Love / Hate relationship              NaN   \n",
            "4                                   I LOVE IT              NaN   \n",
            "\n",
            "  reviews.userProvince    reviews.username  sizes upc     weight  \n",
            "0                  NaN          Cristina M    NaN NaN  205 grams  \n",
            "1                  NaN               Ricky    NaN NaN  205 grams  \n",
            "2                  NaN       Tedd Gardiner    NaN NaN  205 grams  \n",
            "3                  NaN              Dougal    NaN NaN  205 grams  \n",
            "4                  NaN  Miljan David Tanic    NaN NaN  205 grams  \n",
            "\n",
            "[5 rows x 27 columns]\n",
            "id                         0\n",
            "asins                      0\n",
            "brand                      0\n",
            "categories                 0\n",
            "colors                   823\n",
            "dateAdded                  0\n",
            "dateUpdated                0\n",
            "dimension               1032\n",
            "ean                      699\n",
            "keys                       0\n",
            "manufacturer             632\n",
            "manufacturerNumber       695\n",
            "name                       0\n",
            "prices                     0\n",
            "reviews.date             380\n",
            "reviews.doRecommend     1058\n",
            "reviews.numHelpful       697\n",
            "reviews.rating           420\n",
            "reviews.sourceURLs         0\n",
            "reviews.text               0\n",
            "reviews.title             17\n",
            "reviews.userCity        1597\n",
            "reviews.userProvince    1597\n",
            "reviews.username          17\n",
            "sizes                   1597\n",
            "upc                      699\n",
            "weight                   911\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d329678c72c5>:28: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data['reviews.text'] = data['reviews.text'].str.replace('[^a-zA-Z]', ' ')  # Remove non-alphabetic characters\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Amazon Product Review Database.zip')  # 'Amazon Product Review Database.zip' with your actual file name\n",
        "\n",
        "# Display the first few rows to understand the data\n",
        "print(data.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Drop columns that are not needed for analysis\n",
        "columns_to_drop = ['id', 'asins', 'dateUpdated', 'dimension', 'ean', 'keys', 'manufacturerNumber', 'reviews.sourceURLs', 'upc', 'weight']\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Handling missing values\n",
        "# Drop rows with missing values in critical columns\n",
        "data.dropna(subset=['reviews.date', 'reviews.rating', 'reviews.text'], inplace=True)\n",
        "\n",
        "# Convert 'reviews.date' to datetime format\n",
        "data['reviews.date'] = pd.to_datetime(data['reviews.date'])\n",
        "\n",
        "# Handling duplicates\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "# Text cleaning for 'reviews.text' column\n",
        "data['reviews.text'] = data['reviews.text'].astype(str)  # Convert to string\n",
        "data['reviews.text'] = data['reviews.text'].str.replace('[^a-zA-Z]', ' ')  # Remove non-alphabetic characters\n",
        "\n",
        "# Encoding categorical variables\n",
        "# One-hot encoding for 'categories' column\n",
        "data = pd.get_dummies(data, columns=['categories'])\n",
        "\n",
        "# Scale numerical features (if needed)\n",
        "# Example:\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "# data[['reviews.rating', 'reviews.numHelpful']] = scaler.fit_transform(data[['reviews.rating', 'reviews.numHelpful']])\n",
        "\n",
        "# Prepare for modeling\n",
        "# Define X (features) and y (target variable)\n",
        "X = data.drop(['reviews.rating'], axis=1)  # Assuming 'reviews.rating' is the target variable\n",
        "y = data['reviews.rating']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further preprocessing steps and model fitting would be done here\n",
        "\n",
        "# For instance, fitting a model using RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "\n"
      ]
    }
  ]
}